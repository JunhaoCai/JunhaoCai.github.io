<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Redefine">
    <meta name="description" content="Hexo Theme Redefine">
    <meta name="author" content="Jun-ho Chae">
    
    <title>
        
            (NLP) Summary of the input details of embedding layer, LSTM layer. |
        
        Jun-ho Chae&#39;s Blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/c-solid.svg">
    
<link rel="stylesheet" href="/css/fontawesome.min.css">

    
<link rel="stylesheet" href="/css/v5-font-face.min.css">

    
<link rel="stylesheet" href="/css/duotone.min.css">

    
<link rel="stylesheet" href="/css/brands.min.css">

    
<link rel="stylesheet" href="/css/solid.min.css">

    
<link rel="stylesheet" href="/css/css2.css">

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <script id="hexo-configurations">
    let REDEFINE = window.REDEFINE || {};
    REDEFINE.hexo_config = {"hostname":"example.com","root":"/","language":"en","path":"search.json"};
    REDEFINE.theme_config = {"toc":{"enable":true,"number":false,"expand_all":true,"init_open":true},"style":{"primary_color":"#005080","avatar":"/images/c-solid.svg","favicon":"/images/c-solid.svg","article_img_align":"center","right_side_width":"210px","content_max_width":"1000px","nav_color":{"left":"#f78736","right":"#367df7","transparency":35},"hover":{"shadow":true,"scale":false},"first_screen":{"enable":true,"background_image":{"light":"/images/light1111.jpg","dark":"/images/dark111.jpg"},"title_color":{"light":"#fff","dark":"#d1d1b6"},"description":"Welcome to my Blog. Have a nice day! üòä"},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":false}}},"local_search":{"enable":true,"preload":true},"code_copy":{"enable":true},"pjax":{"enable":true},"lazyload":{"enable":true},"version":"0.3.5"};
    REDEFINE.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
  </script>
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fas fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">
    
    <div class="header-content">
        <div class="left">
            
            <a class="logo-title" href="/">
                Jun-ho Chae&#39;s Blog
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                HOME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >
                                ARCHIVES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               target="_blank" rel="noopener" href="https://blog.csdn.net/cjh0318"
                            >
                                LINKS
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/about"
                            >
                                ABOUT
                            </a>
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">HOME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives">ARCHIVES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       target="_blank" rel="noopener" href="https://blog.csdn.net/cjh0318">LINKS</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/about">ABOUT</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="post-page-container">
        <div class="article-content-container">
            <div class="article-title">
                <span class="title-hover-animation"><h1 style="font-size:2rem; font-weight: bold; margin: 10px 0;">(NLP) Summary of the input details of embedding layer, LSTM layer.</h1></span>
            </div>

            
                <div class="article-header">
                    <div class="avatar">
                        <img src="/images/c-solid.svg">
                    </div>
                    <div class="info">
                        <div class="author">
                            <span class="name">Jun-ho Chae</span>
                            
                                <span class="author-label">lol</span>
                            
                        </div>
                        <div class="meta-info">
                            <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fa-duotone fa-pen-line"></i>&nbsp;
        <span class="pc">2022-12-13 00:02:51</span>
        <span class="mobile">2022-12-13 00:02</span>
    </span>
    
    

    
    
    
    
</div>

                        </div>
                    </div>
                </div>
            

            <div class="article-content markdown-body">
                <h1 id="0-Statement-üòÑ"><a href="#0-Statement-üòÑ" class="headerlink" title="0. Statement. üòÑ"></a>0. Statement. üòÑ</h1><p>Today, I summarize the details of the problems I encountered through the NLP experiments I did before. Although it is a small detail, it will determine whether the experiment can go on or not, so it is very important for us. üè´</p>
<h1 id="1-Complete-the-classification-problem-of-the-iris-dataset-using-LSTM-Embedding-üòá"><a href="#1-Complete-the-classification-problem-of-the-iris-dataset-using-LSTM-Embedding-üòá" class="headerlink" title="1. Complete the classification problem of the iris dataset using LSTM + Embedding. üòá"></a>1. Complete the classification problem of the iris dataset using LSTM + Embedding. üòá</h1><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, f1_score</span><br><span class="line"><span class="keyword">from</span> torch.utils.data.dataset <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> torch.utils.data.dataloader <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set random seeds</span></span><br><span class="line">seed = <span class="number">1</span></span><br><span class="line">torch.manual_seed(seed)</span><br><span class="line">torch.cuda.manual_seed(seed)</span><br><span class="line">torch.cuda.manual_seed_all(seed)  <span class="comment"># if you are using multi-GPU.</span></span><br><span class="line">np.random.seed(seed)  <span class="comment"># Numpy module.</span></span><br><span class="line">torch.manual_seed(seed)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Hyperparameters</span></span><br><span class="line">Max_epoch = <span class="number">100</span></span><br><span class="line">batch_size = <span class="number">6</span></span><br><span class="line">learning_rate = <span class="number">0.05</span></span><br><span class="line">path = <span class="string">&quot;Iris.csv&quot;</span></span><br><span class="line">train_rate = <span class="number">0.8</span></span><br><span class="line"></span><br><span class="line">df = pd.read_csv(path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use pandas to mess up the data</span></span><br><span class="line">df = df.sample(frac=<span class="number">1</span>)</span><br><span class="line">cols_feature = [<span class="string">&#x27;SepalLengthCm&#x27;</span>, <span class="string">&#x27;SepalWidthCm&#x27;</span>, <span class="string">&#x27;PetalLengthCm&#x27;</span>, <span class="string">&#x27;PetalWidthCm&#x27;</span>]</span><br><span class="line">df_features = df[cols_feature]</span><br><span class="line">df_categories = df[<span class="string">&#x27;Species&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert category strings to numbers.</span></span><br><span class="line">categories_digitization = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> df_categories:</span><br><span class="line">	<span class="keyword">if</span> i == <span class="string">&#x27;Iris-setosa&#x27;</span>:</span><br><span class="line">		categories_digitization.append(<span class="number">0</span>)</span><br><span class="line">	<span class="keyword">elif</span> i == <span class="string">&#x27;Iris-versicolor&#x27;</span>:</span><br><span class="line">		categories_digitization.append(<span class="number">1</span>)</span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		categories_digitization.append(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">features = torch.from_numpy(np.float32(df_features.values))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(features)</span><br><span class="line"></span><br><span class="line">categories_digitization = np.array(categories_digitization)</span><br><span class="line">categories_digitization = torch.from_numpy(categories_digitization)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;categories_digitization&quot;</span>,categories_digitization)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define MyDataset class, inherit Dataset methods, and override __getitem__() and __len__() methods</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">	<span class="comment"># Initialize the function and get the data</span></span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, datas, labels</span>):</span><br><span class="line">		self.datas = datas</span><br><span class="line">		self.labels = labels</span><br><span class="line"></span><br><span class="line">	<span class="comment"># print(df_categories_digitization)</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># index is the index obtained after dividing the data according to the batchsize, and finally the data and the corresponding labels are returned together</span></span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">		features = self.datas[index]</span><br><span class="line">		categories_digitization = self.labels[index]</span><br><span class="line">		<span class="keyword">return</span> features, categories_digitization</span><br><span class="line"></span><br><span class="line">	<span class="comment"># This function returns the length of the data size, the purpose of the DataLoader to facilitate the division, if you do not know the size, the DataLoader will be a confused face</span></span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">		<span class="keyword">return</span> <span class="built_in">len</span>(self.labels)</span><br><span class="line"></span><br><span class="line">num_train = <span class="built_in">int</span>(features.shape[<span class="number">0</span>] * train_rate)</span><br><span class="line">train_x = features[:num_train]</span><br><span class="line">train_y = categories_digitization[:num_train]</span><br><span class="line">test_x = features[num_train:]</span><br><span class="line">test_y = categories_digitization[num_train:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load the data through MyDataset and return the Dataset object, containing data and labels</span></span><br><span class="line">train_data = MyDataset(train_x, train_y)</span><br><span class="line">test_data = MyDataset(test_x, test_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Read data</span></span><br><span class="line">train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=<span class="literal">True</span>, drop_last=<span class="literal">False</span>, num_workers=<span class="number">0</span>)</span><br><span class="line">test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=<span class="literal">True</span>, drop_last=<span class="literal">False</span>, num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyModel</span>(nn.Module):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">		<span class="built_in">super</span>().__init__()</span><br><span class="line">		self.embedding = nn.Embedding(num_embeddings=<span class="number">100</span>, embedding_dim=<span class="number">300</span>)</span><br><span class="line">		self.lstm = nn.LSTM(input_size=<span class="number">300</span>, hidden_size=<span class="number">128</span>, num_layers=<span class="number">2</span>, batch_first=<span class="literal">True</span>)</span><br><span class="line">		self.fc = nn.Linear(<span class="number">128</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&quot;Just entered into the network:&quot;</span>,x.shape)</span><br><span class="line">		x = self.embedding(x)</span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&quot;After embedding&quot;</span>,x.shape)</span><br><span class="line">		x, _ = self.lstm(x)</span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&quot;After lstm&quot;</span>, x.shape)</span><br><span class="line">		x = self.fc(x[:, -<span class="number">1</span>, :])</span><br><span class="line">		<span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># Instantiated models</span></span><br><span class="line">model = MyModel()</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define loss functions and optimizers</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training Model</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">	<span class="keyword">for</span> step, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_dataloader):</span><br><span class="line">		batch_x, batch_y = batch</span><br><span class="line">		<span class="comment"># Obtain training data and perform pre-processing</span></span><br><span class="line">		<span class="comment"># inputs, targets = get_data()</span></span><br><span class="line">		<span class="comment"># inputs = torch.LongTensor(inputs)</span></span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&quot;batch_x.dtype:&quot;</span>,batch_x.dtype)</span><br><span class="line">		batch_x = batch_x.<span class="built_in">type</span>(torch.LongTensor)</span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&quot;batch_x.dtype:&quot;</span>,batch_x.dtype)</span><br><span class="line"></span><br><span class="line">		x = torch.LongTensor(batch_x)</span><br><span class="line">		<span class="comment"># targets = torch.FloatTensor(targets)</span></span><br><span class="line">		<span class="built_in">print</span>(batch_y.dtype)</span><br><span class="line">		batch_y = batch_y.<span class="built_in">type</span>(torch.LongTensor)</span><br><span class="line">		<span class="built_in">print</span>(batch_y.dtype)</span><br><span class="line">		y = torch.LongTensor(batch_y)</span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&quot;y.shape(type: classes):&quot;</span>,y.shape)</span><br><span class="line"></span><br><span class="line">		<span class="comment"># Clear gradient</span></span><br><span class="line">		optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">		<span class="comment"># Forward propagation</span></span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&quot;x.shape:&quot;</span>,x.shape)</span><br><span class="line">		outputs = model(x)</span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&quot;outputs.shape:&quot;</span>, outputs.shape)</span><br><span class="line"></span><br><span class="line">		<span class="comment"># Calculated losses</span></span><br><span class="line">		loss = criterion(outputs, y)</span><br><span class="line"></span><br><span class="line">		<span class="comment"># Back propagation</span></span><br><span class="line">		loss.backward()</span><br><span class="line"></span><br><span class="line">		<span class="comment"># Update parameters</span></span><br><span class="line">		optimizer.step()</span><br><span class="line"></span><br><span class="line">		<span class="comment"># Output the loss for each epoch</span></span><br><span class="line">		<span class="built_in">print</span>(<span class="string">f&quot;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>: loss = <span class="subst">&#123;loss.item()&#125;</span>&quot;</span>)</span><br><span class="line">model.<span class="built_in">eval</span>()  <span class="comment">#net.eval() is needed for testing</span></span><br><span class="line">test_pred = []</span><br><span class="line">test_true = []</span><br><span class="line"><span class="keyword">for</span> step, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_dataloader):</span><br><span class="line">	batch_x, batch_y = batch</span><br><span class="line">	batch_x = batch_x.<span class="built_in">type</span>(torch.LongTensor)</span><br><span class="line">	x = torch.LongTensor(batch_x)</span><br><span class="line">	logistics = model(x)</span><br><span class="line">	<span class="comment"># Take the largest value in each [].</span></span><br><span class="line">	pred_y = logistics.argmax(<span class="number">1</span>)</span><br><span class="line">	test_true.extend(batch_y.numpy().tolist())</span><br><span class="line">	test_pred.extend(pred_y.detach().numpy().tolist())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;test set prediction <span class="subst">&#123;test_pred&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;test set exact<span class="subst">&#123;test_true&#125;</span>&quot;</span>)</span><br><span class="line">accuracy = accuracy_score(test_true, test_pred)</span><br><span class="line">f1 = f1_score(test_true, test_pred, average = <span class="string">&quot;macro&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Accuracy:<span class="subst">&#123;accuracy&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;F1:<span class="subst">&#123;f1&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://img-blog.csdnimg.cn/98e24481ad074fce87abcbc1593ff464.png"
                      alt="ËØ∑Ê∑ªÂä†ÂõæÁâáÊèèËø∞"
                ></p>
<h1 id="2-The-shape-of-the-embedding-layer-ü§†"><a href="#2-The-shape-of-the-embedding-layer-ü§†" class="headerlink" title="2. The shape of the embedding layer. ü§†"></a>2. The shape of the embedding layer. ü§†</h1><p><strong>The input shape of the embedding layer</strong> is <strong>(batch_size, sequence_length)</strong>. In this case, batch_size represents the number of samples in the batch and sequence_length represents the length of the sequence in each sample. For example, for a text classification task, the sequence may contain words or sentences of words, and sequence_length is the number of words in the sentence.<br>For example, in the following iris datasetüëá, I <strong>extract the first 6 samples as a batch</strong>, <strong>so batch_size &#x3D; 6</strong>, and there are <strong>4 features in the dataset except for Id, so sequence_length is 4</strong>. In summary, <strong>(batch_size, sequence_length) &#x3D; (6, 4).</strong></p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Id, SepalLengthCm, SepalWidthCm, PetalLengthCm, PetalWidthCm, Species</span><br><span class="line"><span class="number">1</span>,<span class="number">5.1</span>,<span class="number">3.5</span>,<span class="number">1.4</span>,<span class="number">0.2</span>,Iris-setosa</span><br><span class="line"><span class="number">2</span>,<span class="number">4.9</span>,<span class="number">3.0</span>,<span class="number">1.4</span>,<span class="number">0.2</span>,Iris-setosa</span><br><span class="line"><span class="number">3</span>,<span class="number">4.7</span>,<span class="number">3.2</span>,<span class="number">1.3</span>,<span class="number">0.2</span>,Iris-setosa</span><br><span class="line"><span class="number">4</span>,<span class="number">4.6</span>,<span class="number">3.1</span>,<span class="number">1.5</span>,<span class="number">0.2</span>,Iris-setosa</span><br><span class="line"><span class="number">5</span>,<span class="number">5.0</span>,<span class="number">3.6</span>,<span class="number">1.4</span>,<span class="number">0.2</span>,Iris-setosa</span><br><span class="line"><span class="number">6</span>,<span class="number">5.4</span>,<span class="number">3.9</span>,<span class="number">1.7</span>,<span class="number">0.4</span>,Iris-setosa</span><br></pre></td></tr></table></figure></div>
<h1 id="3-The-shape-of-the-LSTM-layer-ü•∏"><a href="#3-The-shape-of-the-LSTM-layer-ü•∏" class="headerlink" title="3. The shape of the LSTM layer. ü•∏"></a>3. The shape of the LSTM layer. ü•∏</h1><p><strong>When batch_first&#x3D;True, the input shape of the LSTM layer is (batch_size, sequence_length, input_dim).</strong> In this case, batch_size denotes the number of samples in the batch, sequence_length denotes the length of the sequence in each sample, and input_dim denotes the number of features in each cell. For example, for a text classification task, the sequence may contain words or sentences composed of words. input_dim is the number of features in each word (e.g., the dimensionality of the word vector).<br><strong>The size of num_embeddings is related to the size of the vocabulary.</strong> num_embeddings refers to the number of different words in the vocabulary and is used to initialize the word embedding matrix, so if the vocabulary is large, then num_embeddings should be increased accordingly.üëá<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://img-blog.csdnimg.cn/2cf1ae86e42848d6bf00b0e8f491f8a2.png"
                      alt="ËØ∑Ê∑ªÂä†ÂõæÁâáÊèèËø∞"
                ></p>
<h1 id="4-Why-use-x-x3D-self-fc-x-1-ü§ì"><a href="#4-Why-use-x-x3D-self-fc-x-1-ü§ì" class="headerlink" title="4. Why use x &#x3D; self.fc(x[:, -1, :])? ü§ì"></a>4. Why use x &#x3D; self.fc(x[:, -1, :])? ü§ì</h1><p>The reason for <strong>using x[:, -1, :] is that the LSTM layer processes each cell in the sequence through a circular mechanism and remembers the previous information in the sequence</strong>, so the last cell in the sequence is usually considered to contain the information in the whole sequence and is more easily classified by the classifier.</p>
<h1 id="Finally-ü§©"><a href="#Finally-ü§©" class="headerlink" title="Finally ü§©"></a>Finally ü§©</h1><p>Thank you for the current age of knowledge sharing and the people willing to share it, thank you!</p>

            </div>

            
                <div class="post-copyright-info">
                    <div class="article-copyright-info-container">
    <ul>
        <li>Post titleÔºö(NLP) Summary of the input details of embedding layer, LSTM layer.</li>
        <li>Post authorÔºöJun-ho Chae</li>
        <li>Create timeÔºö2022-12-13 00:02:51</li>
        <li>
            Post linkÔºöhttps://redefine.evanluo.top/2022/12/13/[NLP] Summary of the input details of embedding layer, LSTM layer./
        </li>
        <li>
            Copyright NoticeÔºöAll articles in this blog are licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> unless stating additionally.
        </li>
    </ul>
</div>

                </div>
            

            

            
                <div class="article-nav">
                    
                    
                        <div class="article-next">
                            <a class="next"
                            rel="next"
                            href="/2022/12/13/%5BNLP%5D%20Sentiment%20classification%20using%20LSTMs%20and%20torchtext/"
                            >
                                <span class="title flex-center">
                                    <span class="post-nav-title-item">(NLP) Sentiment classification using LSTMs and torchtext.</span>
                                    <span class="post-nav-item">Next posts</span>
                                </span>
                                <span class="right arrow-icon flex-center">
                                <i class="fas fa-chevron-right"></i>
                                </span>
                            </a>
                        </div>
                    
                </div>
            

            
                <div class="comment-container">
                    <div class="comments-container">
    <div id="comment-anchor"></div>
    <div class="comment-area-title">
        <i class="fas fa-comments">&nbsp;Comments</i>
    </div>
    

        
            

        
    
</div>

                </div>
            
        </div>

        
            <div class="toc-content-container">
                <div class="post-toc-wrap">
    <div class="post-toc">
        <div style="font-size: 1.3rem;margin-top: 0; margin-bottom: 0.8rem; transition-duration: 0.1s;"><i class="fa-solid fa-list"></i> <strong>Contents</strong></div>
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#0-Statement-%F0%9F%98%84"><span class="nav-text">0. Statement. üòÑ</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-Complete-the-classification-problem-of-the-iris-dataset-using-LSTM-Embedding-%F0%9F%98%87"><span class="nav-text">1. Complete the classification problem of the iris dataset using LSTM + Embedding. üòá</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-The-shape-of-the-embedding-layer-%F0%9F%A4%A0"><span class="nav-text">2. The shape of the embedding layer. ü§†</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-The-shape-of-the-LSTM-layer-%F0%9F%A5%B8"><span class="nav-text">3. The shape of the LSTM layer. ü•∏</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-Why-use-x-x3D-self-fc-x-1-%F0%9F%A4%93"><span class="nav-text">4. Why use x &#x3D; self.fc(x[:, -1, :])? ü§ì</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Finally-%F0%9F%A4%A9"><span class="nav-text">Finally ü§©</span></a></li></ol>
    </div>
</div>
            </div>
        
    </div>
</div>


                

            </div>



        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
              <span>2020</span>
              -
            
            2023&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a href="/">Jun-ho Chae</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv">
                        Visitor Count&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                    </span>
                
                
                    <span id="busuanzi_container_site_pv">
                        Totalview&nbsp;<span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="theme-info info-item">
            Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v0.3.5</a>
        </div>
        
        
    </div>
    <link rel="stylesheet" href="//evan.beee.top/css/waline.css"/>
    <script src="//evan.beee.top/js/waline.js"></script>
    
<link rel="stylesheet" href="/css/regular.min.css">

</footer>
        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item page-aside-toggle">
                <i class="fa-duotone fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="go-comment">
                <i class="fa-duotone fa-comments"></i>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/dark-light-toggle.js"></script>



    
<script src="/js/local-search.js"></script>




    
<script src="/js/code-copy.js"></script>




    
<script src="/js/lazyload.js"></script>



<div class="post-scripts pjax">
    
        
<script src="/js/left-side-toggle.js"></script>

<script src="/js/libs/anime.min.js"></script>

<script src="/js/toc.js"></script>

    
</div>


    
<script src="/js/libs/pjax.min.js"></script>

<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            REDEFINE.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            REDEFINE.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            REDEFINE.refresh();
        });
    });
</script>



</body>
</html>
